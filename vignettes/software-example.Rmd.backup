---
title: "Multi-Decision Multi-Criteria Decision Aid Software example"
author: "Gjalt-Jorn Peters"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Multi-Decision Multi-Criteria Decision Aid Software example}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE, echo=FALSE, results='asis'}

knitr::opts_chunk$set(
  echo = FALSE,
  collapse = TRUE,
  comment = "",
  dev="png", 
	dev.args=list(type="cairo"),
	dpi=100
);

options(knitr.kable.NA = '');

### Show code and table of contents label in HTML only
if (knitr::is_html_output()) {
  cat("\n\n# Contents\n\n");
}

ufs::opts$set(ggSaveFigWidth = 4,
              ggSaveFigHeight = 4,
              ggSaveUnits = "in",
              ggBaseSize = 12,
              knitAndSave.catPlot = TRUE,
              knitFig.catPlot = TRUE);

mdmcda::opts$set(ggSaveFigWidth = 4,
                ggSaveFigHeight = 4,
                ggSaveUnits = "in",
                ggBaseSize = 12);

quietGitLabUpdate <- function(x, quiet = TRUE) {
  if (quiet) {
    func <- function(x) invisible(suppressMessages(x));
  } else {
    func <- function(x) return(x);
  }
  func(tryCatch(
        remotes::install_gitlab(x, dependencies=FALSE,
                                quiet=quiet, upgrade=FALSE),
        error=invisible));
}

quietGitLabUpdate("r-packages/yum");
quietGitLabUpdate("r-packages/ufs");
quietGitLabUpdate("r-packages/mdmcda@dev");

### Check for required packages
ufs::checkPkgs("tidyr");
ufs::checkPkgs("readxl");
ufs::checkPkgs("svglite");

### First get the directory where 'dmcda' is installed
currentDir <- system.file(package="mdmcda");

### Specify the path of the example DMCDA files
currentDir <- file.path(currentDir, "extdata");

### During vignette development, to avoid requiring constant package building
currentDir <- here::here('inst');

### Set paths with files
dataDir <- file.path(currentDir,
                     "extdata",
				          	 "software-example");

```

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

# Loading data

## Criteria (outcomes of chosen policy)

The following tree of criteria was established:

```{r load-criteria, message=FALSE, comment=""}

criteria <-
  mdmcda::read_criteria_from_xl(file.path(dataDir,
                                         "software-example-fullCriteriaDf.xlsx"),
                               showGraphs = FALSE);

print(criteria$criteriaTree);

```

These criteria have a hierarchical structure to facilitate weighing them efficiently. They are clustered based on domain, such that each outcome can be considered an indicator of the criterion cluster. For example, prevalence in the general population, and frequency and intensity of use by MDMA users are both indicative of MDMA use (the overarching cluster). Therefore, if a decision maker values MDMA use as an outcome, that cluster can receive a high weight. The relative contribution of the two indicators can then be finetuned by setting the weights of the individual criteria. Similarly, a decision maker who does not want MDMA use to play a large role when determining their policy can set the cluster weight to a low value or to zero. The latter would immediately take both  contained criteria out of the total scores computed for the scenarios (policy models).

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

## Estimates

### Reading estimates

```{r load-estimates, fig.width=10, results="asis"}

estimates <-
  mdmcda::read_performance_tables(input = file.path(dataDir),
                                 regex = "^performance_subtable_for_",
                                 recursive = FALSE);

```

In total, `r nrow(estimates$multiEstimateDf)` estimates were read. These estimates express estimated effects of `r length(unique(estimates$multiEstimateDf$decision_id))` decisions (policy instruments), that together comprise a total of `r nrow(unique(estimates$multiEstimateDf[, c('decision_id', 'alternative_value')]))` alternatives (policy options), on a total of `r length(unique(estimates$multiEstimateDf$criterion_id))` criteria (outcomes).

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

## Weights

To set weights, all experts submitted individually determined weights for each outcome and each outcome cluster on a scale from 0-100, by first setting the weight of the most important cluster and the most important outcome in each cluster to 100, and then setting the weight of the other clusters and outcomes according to their relative importance compared to the most important cluster or outcome  (e.g. an outcome half as important as the most important outcome in the same cluster would get a weight of 50). These individually set weights will later be used to compute consensus weights that will be used in the rest of the procedures.

```{r load-weights, fig.width=10, results="asis"}

weights <-
  mdmcda::read_weights_from_xl(
    input = file.path(dataDir,
                      "software-example-criteria-weights.xlsx")
  );

```

Weights were loaded from `r length(weights$individualWeights)` scorers with identifiers `r ufs::vecTxtQ(weights$scorerTxt)`.

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

## Scenarios

```{r load-scenarios, fig.width=10, results="asis"}

# scenariosFile <-
#   file.path(dataDir,
#             "example-scenario-definitions.xlsx");
# 
# scenarios <-
#   as.data.frame(readxl::read_excel(scenariosFile,
#                                    sheet = 1));

```

`r #ncol(scenarios)-4` scenarios (policy models) were read (`r # ufs::vecTxtQ(tail(colnames(scenarios), -4))`)

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

# Preparing data

In this section, the imported data are preprocessed.

## Process confidence scores {.tabset}

### Overview

During the scoring days, each scorer expressed their confidence in each completed performance sub-table. Processing the confidence scores generates many visualisations. These can be inspected in the second tab.

### Plots

```{r process-confidences, results="asis"}

###----------------------------------------------------------------------------
### Clean up confidences
###----------------------------------------------------------------------------

estimates <-
  mdmcda::process_confidences(estimates);

```

<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->
<!---------------------------------------------------------------------------->

## Process weights {.tabset}

### Overview

The individual weights are now averaged, and then rescaled such that the most important outcome and cluster again had a weight of 100 (i.e. to the same metric used by the individual scorers). All outcome weights are then divided by 100 and multiplied with the weight of the corresponding clusters.

After this procedure, the most important outcome in each cluster has the weight of its cluster, and the other outcomes’ weights decrease proportionally. Finally, every weight is divided by the sum of all weights and multiplied by 100, so that every final weight expresses the relative contribution of the corresponding outcome in each model’s final scores.

Again, the visualisations can be inspected in the second tab.

### Visualisations

```{r process-weights, results="asis"}

###----------------------------------------------------------------------------
### Aggregate weight estimates
###----------------------------------------------------------------------------

weightsMeansAndSDs <- mdmcda::weightsMeansAndSDs(weights);

###----------------------------------------------------------------------------
### Combine with criteria tree to accumulate over the hierachy
###----------------------------------------------------------------------------

weightsMeansAndSDs <-
  mdmcda::combine_weights_and_criteria(
    weightsMeansAndSDs,
    criteria,
    weightCols = c(raw = 'weight_mean_proportion',
                   rescaled = 'weight_mean_rescaled_proportion'));

###----------------------------------------------------------------------------
### Weight plots
###----------------------------------------------------------------------------

# weightsByParentCriterionPlots <-
#   lapply(weights$parentCriteria, function(criteriaCluster_id) {
#     return(mdmcda::scorerWeightPlot(weights = weights,
#                                    weightsMeansAndSDs = weightsMeansAndSDs,
#                                    criteriaCluster_id = criteriaCluster_id,
#                                    meanColumns = c("weight_mean",
#                                                    "weight_mean_rescaled"),
#                                    meanColors = c("black", "black"),
#                                    meanAlphas = c(0.2, 1),
#                                    title = paste0("Weights for ", criteriaCluster_id)));
#   });
# names(weightsByParentCriterionPlots) <- weights$parentCriteria;

###----------------------------------------------------------------------------
### Compile weight profile
###----------------------------------------------------------------------------

weightProfiles <-
  mdmcda::create_weight_profile(weightsMeansAndSDs = weightsMeansAndSDs,
                               criteria = criteria,
                               profileName = "meanWeights");
weightProfileNames <- names(weightProfiles);

```

## Final weights

```{r weight-overview-add-clusters}

weightsMeansAndSDs$isCluster <-
  weightsMeansAndSDs$criterion_id %in% weightsMeansAndSDs$parentCriterion_id;

```

### Cluster weights

The weights for the criteria clusters are:

```{r weight-overview-criteria-clusters}

tmpDf <- weightsMeansAndSDs[weightsMeansAndSDs$isCluster, ];

knitr::kable(tmpDf[order(tmpDf$rescaled_total, decreasing = TRUE),
                   c('criterion_id', 'rescaled_product')], row.names=FALSE);
rm(tmpDf);

```

### Criteria weights

The weights for the criteria are:

```{r weight-overview-criteria}

tmpDf <- weightsMeansAndSDs[!weightsMeansAndSDs$isCluster, ];

knitr::kable(tmpDf[order(tmpDf$rescaled_total, decreasing = TRUE),
                   c('criterion_id', 'rescaled_total')], row.names=FALSE);
rm(tmpDf);

```


# Results

```{r compute-scores-per-scenario, results="asis"}

###----------------------------------------------------------------------------
### Weigh estimates into scores and compute scores per scenario
###----------------------------------------------------------------------------

### Some preparation
criterionNames <- criteria$convenience$childCriteriaByCluster;

### Create dataframe for the weighed estimates
weighedEstimates <-
  mdmcda::build_weighed_estimate_df(multiEstimateDf = estimates$multiEstimateDf,
                                    criterionNames = criterionNames,
                                    scorer = "all",
                                    setMissingEstimates=0);

### Actually weigh the estimates
weighedEstimates <-
  mdmcda::weigh_estimates_by_profile(weighed_estimate_df = weighedEstimates,
                                     weight_profiles = weightProfiles);

### Add weights and weighed estimates to multiEstimateDf
for (currentWeightProfile in weightProfileNames) {
  
  estimates$multiEstimateDf[[paste0(currentWeightProfile, "_weight")]] <-
    weightProfiles[[currentWeightProfile]][estimates$multiEstimateDf$criterion_id];
  
  estimates$multiEstimateDf[[paste0(currentWeightProfile, "_weighed_estimate")]] <-
    estimates$multiEstimateDf$all *
    estimates$multiEstimateDf[[paste0(currentWeightProfile, "_weight")]];
  
}

###----------------------------------------------------------------------------
### Performance tables
###----------------------------------------------------------------------------

if (length(unique(weighedEstimates$decision_id)) == 1) {
  performanceTables <-
    tidyr::pivot_wider(weighedEstimates[,
                                        c("alternative_value",
                                          "criterion_id",
                                          "meanWeights_weighed_estimate")],
                       id_cols="alternative_value",
                       names_from="criterion_id",
                       values_from="meanWeights_weighed_estimate");
  names(performanceTables) <- unique(weighedEstimates$decision_id);
} else {
  performanceTables <-
    lapply(unique(weighedEstimates$scenario_id),
           function(currentScenario) {
    return(tidyr::pivot_wider(weighedEstimates[weighedEstimates$scenario_id==currentScenario,
                                               c("decision_id",
                                                 "criterion_id",
                                                 "meanWeights_weighed_estimate")],
                              id_cols="decision_id",
                              names_from="criterion_id",
                              values_from="meanWeights_weighed_estimate"));
           });
  names(performanceTables) <- unique(weighedEstimates$scenario_id);
}

```

## Overview of all weighed estimates for each decision and criterion

Because in this example, we have only 54 estimates, it's feasible to show the overview of all estimates, their weight, and the final scores.

```{r all-weighed-estimates}
knitr::kable(estimates$multiEstimateDf[, c('decision_id', 'alternative_value', 'criterion_id', 'all', "meanWeights_weight", "meanWeights_weighed_estimate")],
             col.names = c("Decision", "Alternative", "Criterion",
                           "Estimate", "Weight", "Score"));
```

## Scores for each defined scenario

Every estimate for an effect of an instrument’s option on an outcome is multiplied with that outcome’s weight. Then, for every policy model, the scores for that model’s selected instrument options are summed to compute each model’s total score. In addition, the highest- and lowest-scoring options for each instrument are identified and combined into the optimal and worst models (i.e. the highest and lowest possible achievable scores).

```{r best-scenario, results="asis"}

###----------------------------------------------------------------------------
### Best scenario
###----------------------------------------------------------------------------

### Do the computations
scores_per_alternative <-
  mdmcda::compute_scores_per_alternative(multiEstimateDf = estimates$multiEstimateDf,
                                        weightProfiles = weightProfiles);
bestAlternatives <-
  mdmcda::compute_best_alternatives(scores_per_alternative=scores_per_alternative);
worstAlternatives <-
  mdmcda::compute_worst_alternatives(scores_per_alternative=scores_per_alternative);

bestAlternatives$alternative_label <-
  unlist(lapply(1:nrow(bestAlternatives),
         function(i) {
           alternative <- as.character(bestAlternatives$alternative_id[i]);
           decision <- as.character(bestAlternatives$decision_id[i]);
           if (grepl(" or ",
                     alternative)) {
             alternatives <- unlist(strsplit(alternative,
                                             " or "));
             return(ufs::vecTxtQ(estimates$alternativeValues[[decision]][alternatives]));
           } else {
             return(paste0("'", estimates$alternativeValues[[decision]][[alternative]],
                           "'"));
           }
         }));

###----------------------------------------------------------------------------
### Add scenario with best scores to list of scenarios
###----------------------------------------------------------------------------

bestScenario <-
  as.numeric(gsub("^.*\\s(\\d+)$",
                  "\\1",
                  bestAlternatives$alternative_id));
names(bestScenario) <- bestAlternatives$decision_id;

worstScenario <-
  as.numeric(gsub("^.*\\s(\\d+)$",
                  "\\1",
                  worstAlternatives$alternative_id));
names(worstScenario) <- worstAlternatives$decision_id;

```

### Optimal model

The highest possible score is `r sum(bestAlternatives$score)`, which is achieved by the following scenario:

```{r best-scenario-show-table}
knitr::kable(bestAlternatives[bestAlternatives$weightProfile=="meanWeights",
                              c("decision_id", "alternative_id", "alternative_label", "score")],
             row.names = FALSE);
```

# Visualisations

```{r main-result-visualisations, results="asis", eval=FALSE}

###----------------------------------------------------------------------------
###----------------------------------------------------------------------------
### Visualisations
###----------------------------------------------------------------------------
###----------------------------------------------------------------------------

###----------------------------------------------------------------------------
### Produce heatmaps
###----------------------------------------------------------------------------

weighedEstimates$parentCriterion_id <-
  criteria$convenience$parentCriterionIds_by_childId[
    as.character(weighedEstimates$criterion_id)
  ];

heatmaps <-
  lapply(weightProfileNames,
         function(weightprofile_id) {
           scenarios <-
             unique(weighedEstimates$scenario_id)
           
           res <-
             lapply(scenarios,
                    function(currentScenario) {

                      return(
                        mdmcda::performanceTable_heatmap(
                          weighedEstimates,
                          estimateCol = paste0(weightprofile_id,
                                               "_weighed_estimate"),
                          scenario_id = currentScenario
                        )
                      );
                      
                    });
           
           return(stats::setNames(res,
                                  nm = scenarios));
           
         });

names(heatmaps) <- weightProfileNames

cat("\n\n## Heatmaps showing all weighes estimates for each policy model\n\n");

for (weightprofile_id in names(heatmaps)) {
  
  ufs::cat0("\n\n### Weighing profile: ", weightprofile_id, "\n\n");
  
  for (scenario_id in names(heatmaps[[weightprofile_id]])) {

    ufs::cat0("\n\n#### Policy model: ", scenario_id, "\n\n");
    
    ufs::knitFig(heatmaps[[weightprofile_id]][[scenario_id]],
                 figCaption = paste0("Heatmap for scenario ",
                                     scenario_id,
                                     " in weight profile ",
                                     weightprofile_id));
  }
}

###----------------------------------------------------------------------------
### Produce barcharts
###----------------------------------------------------------------------------

barcharts <-
  stats::setNames(lapply(weightProfileNames,
         function(currentWeightProfile) {
  return(stats::setNames(
    lapply(unique(weighedEstimates$scenario_id),
           function(scenario_id) {
             return(mdmcda::scoreBarchart_decisions_criteria(weighedEstimates,
                                                            scenario_id=scenario_id,
                                                            estimateCol=paste0(currentWeightProfile,
                                                                               "_weighed_estimate"),
                                                            xLab = "Policy model",
                                                            yLab = "Score",
                                                            title = "Model comparison"));
    }),
    unique(weighedEstimates$scenario_id)));
}), weightProfileNames);

cat("\n\n## Bar charts for instruments (x) and scores (y) by criterion (color)\n\n");

for (weightprofile_id in names(barcharts)) {
  ufs::cat0("\n\n### Weighing profile: ", weightprofile_id, "\n\n");
  for (scenario_id in names(barcharts[[weightprofile_id]])) {
    ufs::cat0("\n\n#### Policy model: ", scenario_id, "\n\n");
    ufs::knitFig(barcharts[[weightprofile_id]][[scenario_id]],
                 figCaption = paste0("Bar chart for scenario ",
                                      scenario_id,
                                      " in weight profile ",
                                      weightprofile_id));
  }
}

###----------------------------------------------------------------------------
### Barcharts to compare scenarios; summing scores per decision
###----------------------------------------------------------------------------

cat("\n\n## Bar charts by scenario (policy model)\n\n");

barcharts_aggregated <-
  stats::setNames(lapply(weightProfileNames,
                         function(currentWeightProfile) {
                           res <- list();
                           
                           ufs::cat0("\n\n### Weight profile: ", currentWeightProfile, "\n\n");

                           res$byDecision <-
                             mdmcda::scoreBarchart_scenarios_criteria(
                               weighedEstimates,
                               estimateCol = paste0(currentWeightProfile,
                                                    "_weighed_estimate"),
                               title = paste0("Comparison bar chart for ",
                                              currentWeightProfile)
                             );

                           res$byCriterion <-
                             mdmcda::scoreBarchart_scenarios_decisions(
                               weighedEstimates,
                               estimateCol = paste0(currentWeightProfile,
                                                    "_weighed_estimate"),
                               title = paste0("Comparison bar chart for ",
                                              currentWeightProfile)
                             );

                           cat("\n\n### Bar chart for models (x) and scores (y) by outcome (color)\n\n");

                           ufs::knitFig(
                             res$byDecision,
                             figCaption = paste0(
                               "Bar chart, aggregated by decision, ",
                               "for weight profile ",
                               currentWeightProfile
                             ));
                           
                           cat("\n\n### Bar chart for models (x) and scores (y) by instrument (color)\n\n");

                           ufs::knitFig(
                             res$byCriterion,
                             figCaption = paste0(
                               "Bar chart, aggregated by criterion, ",
                               "for weight profile ",
                               currentWeightProfile
                             ));

                           return(res);
                           
                         }), weightProfileNames);

```

# Sensitivity analyses

## Weight-based

In these sensitivity analyses, the weights of each individual scorer were applied, after which the total score for each scenario was then computed again. The results were then plotted.

```{r sensitivity-analyses-based-on-weights, results="asis", eval=FALSE}

###----------------------------------------------------------------------------
###----------------------------------------------------------------------------
### Weight sensitivity analyses
###----------------------------------------------------------------------------
###----------------------------------------------------------------------------

wbsa <-
  mdmcda::weight_based_sensitivity_analysis(multiEstimateDf = multiEstimateDf,
                                           weightsMeansAndSDs = weightsMeansAndSDs,
                                           weighedEstimates = weighedEstimates,
                                           criteria = criteria,
                                           scenarioDefinitions = scenarioDefinitions,
                                           weightCols = c(rescaled = 'weight_mean_rescaled_proportion'));

# for (i in names(wbsa$weight_mean_rescaled_proportion)) {
#   title1 <- paste0("Sensitivity analysis (weight-based) score plot for ", i);
#   title2 <- paste0("Sensitivity analysis (weight-based) rank plot for ", i);
#   ufs::knitFig(wbsa$weight_mean_rescaled_proportion[[i]]$scorePlot +
#                  ggplot2::labs(title = title1),
#                figCaption = title1);
# 
#   ufs::knitFig(wbsa$weight_mean_rescaled_proportion[[i]]$rankPlot +
#                  ggplot2::labs(title = title2),
#                figCaption = title2);
# 
# }

# ### Create weight profiles for each scorer who provided weights
# scorerWeights <- list();
# scorerWeightProfiles <- list();
# for (currentScorer in weights$scorerTxt[1:3]) {
#   scorerWeights[[currentScorer]] <-
#     mdmcda::scorerWeights_to_profile(weights = weights,
#                                     scorer = currentScorer,
#                                     criteria = criteria);
#   scorerWeights[[currentScorer]]$weight <-
#     scorerWeights[[currentScorer]][[paste0(currentScorer,
#                                            "_weight_total_proportion")]] * 100;
#   scorerWeightProfiles[[currentScorer]] <-
#     stats::setNames(scorerWeights[[currentScorer]]$weight,
#                     scorerWeights[[currentScorer]]$criterion_id);
#   scorerWeightProfiles[[currentScorer]] <-
#     scorerWeightProfiles[[currentScorer]][!is.na(scorerWeightProfiles[[currentScorer]])]
# }
# 
# ### Add new weights
# weighedEstimates_withScorerWeights <-
#   mdmcda::add_weights(weighedEstimates = weighedEstimates,
#                      weightProfiles = scorerWeightProfiles,
#                      weightProfileNames = names(scorerWeightProfiles));
# 
# ### Compute scenario scores
# scoresPerScenario_withScorerWeights <-
#   mdmcda::scores_by_scenario(weighedEstimates = weighedEstimates_withScorerWeights,
#                             estimateCols = paste0(names(scorerWeightProfiles),
#                                                   '_weighed_estimate'));
# 
# scoresPerScenario_withScorerWeights_df <-
#   do.call(
#     rbind,
#     lapply(names(scorerWeightProfiles),
#            function(scorer) {
#              estimateCol <- paste0(scorer,
#                                    '_weighed_estimate');
#              res <-
#                as.data.frame(
#                  scoresPerScenario_withScorerWeights[[estimateCol]]
#                );
#              res$scorer <- as.numeric(gsub("[a-zA-Z]*", "", scorer));
#              names(res) <- c("scenario_id", "score", "scorer");
#              scenarioLabels <- res$scenario_id[!duplicated(res$scenario_id)];
#              scenarioOrder <- seq_along(scenarioLabels);
#              res$scenario_id <-
#                factor(res$scenario_id,
#                       levels = scenarioOrder,
#                       labels = scenarioLabels[scenarioOrder],
#                       ordered=TRUE);
#              res$rank <- rank(res$score);
#              return(res);
#            })
#     );
# 
# weightSensitivityAnalyses_scorePlot <-
#   ggplot2::ggplot(data = scoresPerScenario_withScorerWeights_df,
#                   mapping = ggplot2::aes_string(x = "scorer",
#                                                 y = "score",
#                                                 group = "scenario_id",
#                                                 color = "scenario_id")) +
#   ggplot2::geom_line(size=1) +
#   ggplot2::scale_color_viridis_d(end=.9) +
#   ggplot2::theme_minimal();
# 
# ufs::knitFig(weightSensitivityAnalyses_scorePlot,
#              figCaption = "Weight sensitivity analysis - scores");
# 
# rankBreaks <-
#   sort(unique(scoresPerScenario_withScorerWeights_df$rank));
# rankLabels <-
#   c("Worst", rep("", length(rankBreaks) - 2), "Best");
# 
# weightSensitivityAnalyses_rankPlot <-
#   ggplot2::ggplot(data = scoresPerScenario_withScorerWeights_df,
#                   mapping = ggplot2::aes_string(x = "scorer",
#                                                 y = "rank",
#                                                 group = "scenario_id",
#                                                 color = "scenario_id")) +
#   ggplot2::geom_line(size=1) +
#   ggplot2::scale_color_viridis_d(end = .9) +
#   ggplot2::scale_y_continuous(breaks=rankBreaks,
#                               labels=rankLabels) +
#   ggplot2::theme_minimal();
# 
# ufs::knitFig(weightSensitivityAnalyses_rankPlot,
#              figCaption = "Weight sensitivity analysis - ranks");

```



## Confidence-based

In these sensitivity analyses, 10% of the estimates about which the think tank expressed the least confidence were sequentially set to the minimum possible value of the corresponding outcome, to the maximum possible value for the corresponding outcome, and to zero. The total score for each scenario was then computed again.

```{r sensitivity-analyses-based-on-confidence, results="asis", eval=FALSE}

###----------------------------------------------------------------------------
###----------------------------------------------------------------------------
### Confidence Sensitivity analyses
###----------------------------------------------------------------------------
###----------------------------------------------------------------------------

confidenceBasedSensitivityAnalysis <- list();

confidenceBasedSensitivityAnalysis$setToMin <-
  mdmcda::confidence_based_sensitivity_analysis(
    multiEstimateDf = estimates$multiEstimateDf,
    collapsedConfidences = estimates$collapsedConfidences,
    criteria = criteria,
    scenarioDefinitions = scenarioDefinitions,
    weightProfiles = weightProfiles,
    transformationFunction = mdmcda::setToMin
  );

confidenceBasedSensitivityAnalysis$setToMax <-
  mdmcda::confidence_based_sensitivity_analysis(
    multiEstimateDf = estimates$multiEstimateDf,
    collapsedConfidences = estimates$collapsedConfidences,
    criteria = criteria,
    scenarioDefinitions = scenarioDefinitions,
    weightProfiles = weightProfiles,
    transformationFunction = mdmcda::setToMax
  );

confidenceBasedSensitivityAnalysis$setToZero <-
  mdmcda::confidence_based_sensitivity_analysis(
    multiEstimateDf = estimates$multiEstimateDf,
    collapsedConfidences = estimates$collapsedConfidences,
    criteria = criteria,
    scenarioDefinitions = scenarioDefinitions,
    weightProfiles = weightProfiles,
    transformationFunction = mdmcda::setToZero
  );

###----------------------------------------------------------------------------
### View results
###----------------------------------------------------------------------------

ufs::knitFig(confidenceBasedSensitivityAnalysis$setToMin$scorePlot,
             figCaption = "Sensitity analysis (confidence-based) score plot when setting estimates to criteria minima");

ufs::knitFig(confidenceBasedSensitivityAnalysis$setToMin$rankPlot,
             figCaption = "Sensitity analysis (confidence-based) rank plot when setting estimates to criteria minima");


ufs::knitFig(confidenceBasedSensitivityAnalysis$setToMax$scorePlot,
             figCaption = "Sensitity analysis (confidence-based) score plot when setting estimates to criteria maxima");


ufs::knitFig(confidenceBasedSensitivityAnalysis$setToMax$rankPlot,
             figCaption = "Sensitity analysis (confidence-based) rank plot when setting estimates to criteria maxima");


ufs::knitFig(confidenceBasedSensitivityAnalysis$setToZero$scorePlot,
             figCaption = "Sensitity analysis (confidence-based) score plot when setting estimates to zero");


ufs::knitFig(confidenceBasedSensitivityAnalysis$setToZero$rankPlot,
             figCaption = "Sensitity analysis (confidence-based) rank plot when setting estimates to zero");


```


<!---------------------------------------------------------------------------->
<!-- Relocating table of contents and tweaking some styles
<!---------------------------------------------------------------------------->

<script>
// Move TOC to the Table of Contents heading (with id "contents")
$(function() {
  $( "#TOC" ).insertAfter( $( "#contents" ) );
});
</script>

<style>
.svg-figure {
  width: 100%;
}
</style>

<!---------------------------------------------------------------------------->
<!-- End of file ------------------------------------------------------------->
<!---------------------------------------------------------------------------->

